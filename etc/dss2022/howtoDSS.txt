
=== psql_history_edited.txt
# initial creation of dev and prod dbs on proxy server
create database netxdb;
create role netx with password '<password-prod>' login;
grant all on database netxdb to netx;

create database netxdb_dev;
create role netx_dev with password '<password-dev>' login;
grant all on database netxdb_dev to netx_dev;

# reset password
# alter role netx with password '<password>';
# or, drop and create afresh
# drop role netx;
# create role ...

=== create-netxview.sql

DROP TABLE IF EXISTS public.netxview;

CREATE TABLE public.netxview (
    accession_number text,
    object_name text,
    taxon text,
    object_title text[],
    prod_date text[],
    materials text[],
    prod_technique text[],
    dimensions text,
    phys_desc text,
    content_desc text,
    brief_desc text,
    obj_prod_org text[],
    obj_prod_person text[],
    content_concepts text[],
    content_persons text[],
    assoc_persons text[],
    content_orgs text[],
    assoc_orgs text[],
    content_place text[],
    assoc_place text[],
    object_prod_place text[],
    field_coll_place text,
    cult_context text[],
    exhibitions text[],
    ip_status text,
    credit_line text[],
    moddate timestamp
);

CREATE INDEX idx_netxview_accession_number ON public.netxview USING btree (accession_number);
CREATE INDEX idx_netxview_moddate ON public.netxview USING btree (moddate);


=== copy.sql

\copy netxview (
object_name,accession_number,taxon,phys_desc,content_desc,field_coll_place,ip_status,
moddate,cult_context,assoc_orgs,assoc_persons,assoc_place,materials,obj_prod_org,
obj_prod_person,object_prod_place,object_title,prod_technique,content_concepts,
content_place,content_persons,content_orgs,exhibitions,dimensions,credit_line,prod_date
) FROM '/home/webapps/webapps/etc/dss2022/netxview.csv'
DELIMITER E'\t'
CSV HEADER

== extract_and_reload_db.sh 

# extract metadata and load into netxdb
source pgvars.sh
echo "copying 4solr.omca.public.csv.gz and extracting and massaging columns..."
cp ~webapps/solr-pipelines/4solr.omca.public.csv.gz .
gunzip -f 4solr.omca.public.csv.gz 
cut -f 4,3,7,33,74,28,34,52,15,16,30,31,40,42,26,43,25,41,27,32,18,24,44,20,58,23 4solr.omca.public.csv > netx-extract.csv
python convert.py netx-extract.csv netxview.csv
echo "`wc -l netxview.csv` rows (including header) extracted from '4solr file' containing `wc -l 4solr.omca.public.csv` lines"
psql -f create-netxview.sql
echo "netxview table recreated."
perl -i -pe 's/\\"//g' netxview.csv
psql -f copy.sql
rm 4solr.omca.public.csv  netx-extract.csv netxview.csv


== a few rows from the netxview table

(venv) webapps@cspace1804:~/webapps/etc/dss2022$ source pgvars.sh 
(venv) webapps@cspace1804:~/webapps/etc/dss2022$ psql

netxdb=> select accession_number,object_name,materials,moddate from netxview limit 5;
 accession_number |   object_name    |            materials            |         moddate         
------------------+------------------+---------------------------------+-------------------------
 H69.38.1858      | subdivision map  |                                 | 2021-10-12 21:03:16.369
 H99.75.51        | chandelier       | {'steel','tin','brass','glass'} | 2016-01-12 16:02:42.549
 H69.459.643      | lantern slide    | {'glass'}                       | 2015-12-20 16:09:51.563
 H72.61.17HH      | photograph       |                                 | 2018-02-17 05:42:07.269
 S93.15.12919     | 35mm color slide |                                 | 2016-02-13 11:16:30.453
(5 rows)

